{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Convolutional Neural Network - CNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* To classify the image set\n",
        "* To test the performance of the classification using resizing vs resizing + padding\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* CSVs outputted from ETL for resizing and resizing + padding\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Write here which files, code or artefacts you generate by the end of the notebook \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* If you have any additional comments that don't fit in the previous bullets, please state them here. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import base64\n",
        "import cv2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\Eddie\\\\Documents\\\\CodeInstitute Workspace\\\\Capstone Project\\\\jupyter_notebooks'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "if os.path.basename(current_dir).lower() == \"jupyter_notebooks\":\n",
        "    os.chdir(os.path.dirname(current_dir))\n",
        "    print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\Eddie\\\\Documents\\\\CodeInstitute Workspace\\\\Capstone Project'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load CSV files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subfolder</th>\n",
              "      <th>image</th>\n",
              "      <th>grey_image</th>\n",
              "      <th>luminance</th>\n",
              "      <th>contrast</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>anger</td>\n",
              "      <td>iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAIAAAAxBA+LAA...</td>\n",
              "      <td>iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAAAAACbDccAAA...</td>\n",
              "      <td>202.218752</td>\n",
              "      <td>42.869499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>anger</td>\n",
              "      <td>iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAIAAAAxBA+LAA...</td>\n",
              "      <td>iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAAAAACbDccAAA...</td>\n",
              "      <td>134.196622</td>\n",
              "      <td>101.303135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>anger</td>\n",
              "      <td>iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAIAAAAxBA+LAA...</td>\n",
              "      <td>iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAAAAACbDccAAA...</td>\n",
              "      <td>109.144209</td>\n",
              "      <td>51.433215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>anger</td>\n",
              "      <td>iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAIAAAAxBA+LAA...</td>\n",
              "      <td>iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAAAAACbDccAAA...</td>\n",
              "      <td>140.261702</td>\n",
              "      <td>89.338355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>anger</td>\n",
              "      <td>iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAIAAAAxBA+LAA...</td>\n",
              "      <td>iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAAAAACbDccAAA...</td>\n",
              "      <td>143.852701</td>\n",
              "      <td>81.434234</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  subfolder                                              image  \\\n",
              "0     anger  iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAIAAAAxBA+LAA...   \n",
              "1     anger  iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAIAAAAxBA+LAA...   \n",
              "2     anger  iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAIAAAAxBA+LAA...   \n",
              "3     anger  iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAIAAAAxBA+LAA...   \n",
              "4     anger  iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAIAAAAxBA+LAA...   \n",
              "\n",
              "                                          grey_image   luminance    contrast  \n",
              "0  iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAAAAACbDccAAA...  202.218752   42.869499  \n",
              "1  iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAAAAACbDccAAA...  134.196622  101.303135  \n",
              "2  iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAAAAACbDccAAA...  109.144209   51.433215  \n",
              "3  iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAAAAACbDccAAA...  140.261702   89.338355  \n",
              "4  iVBORw0KGgoAAAANSUhEUgAAAlgAAAJYCAAAAACbDccAAA...  143.852701   81.434234  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_resize = pd.read_csv(\"./Data/Processed/df_resized.csv\")\n",
        "df_resize_padding = pd.read_csv(\"./Data/Processed/df_resized_padded.csv\")\n",
        "\n",
        "# Display the first few rows of each DataFrame\n",
        "df_resize.head()\n",
        "df_resize_padding.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#convert back to numpy arrays\n",
        "def base64_to_cv2_array(b64_string):\n",
        "    # Decode base64 → bytes\n",
        "    img_bytes = base64.b64decode(b64_string)\n",
        "\n",
        "    # Convert bytes → 1D uint8 array (image buffer)\n",
        "    img_array = np.frombuffer(img_bytes, dtype=np.uint8)\n",
        "\n",
        "    return cv2.imdecode(img_array, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "df_resize['image'] = df_resize['image'].apply(lambda x: base64_to_cv2_array(x))\n",
        "df_resize['grey_image'] = df_resize['grey_image'].apply(lambda x: base64_to_cv2_array(x))\n",
        "\n",
        "df_resize_padding['image'] = df_resize_padding['image'].apply(lambda x: base64_to_cv2_array(x))\n",
        "df_resize_padding['grey_image'] = df_resize_padding['grey_image'].apply(lambda x: base64_to_cv2_array(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Encode labels and split data into training, validation, and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#encode labels\n",
        "encoder = LabelEncoder()\n",
        "df_resize['encoded_labels'] = encoder.fit_transform(df_resize['subfolder'])\n",
        "df_resize_padding['encoded_labels'] = encoder.fit_transform(df_resize_padding['subfolder'])\n",
        "\n",
        "#split data into training, validation, and testing\n",
        "train_df_resize, temp_df_resize = train_test_split(\n",
        "    df_resize, test_size=0.4, random_state=1, stratify=df_resize['encoded_labels']\n",
        ")\n",
        "val_df_resize, test_df_resize = train_test_split(\n",
        "    temp_df_resize, test_size=0.75, random_state=1, stratify=temp_df_resize['encoded_labels']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_resize['encoded_labels'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Colour images - resized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Eddie\\Documents\\CodeInstitute Workspace\\Capstone Project\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(600, 600, 3)),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(6, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "stacked_images = np.stack(train_df_resize['image'].values).astype('float16')/255.0\n",
        "stacked_labels = np.stack(train_df_resize['encoded_labels'].values)\n",
        "stacked_val_images = np.stack(val_df_resize['image'].values).astype('float16')/255.0\n",
        "stacked_val_labels = np.stack(val_df_resize['encoded_labels'].values)\n",
        "stacked_test_images = np.stack(test_df_resize['image'].values).astype('float16')/255.0\n",
        "stacked_test_labels = np.stack(test_df_resize['encoded_labels'].values)\n",
        "\n",
        "#model.fit(stacked_images, stacked_labels, epochs=5, validation_data=(stacked_val_images, stacked_val_labels))\n",
        "\n",
        "#test_loss, test_accuracy = model.evaluate(stacked_test_images, stacked_test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37s/step - accuracy: 0.1669 - loss: 34.1920 "
          ]
        },
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 494. MiB for an array with shape (120, 600, 600, 3) and data type float32",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstacked_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstacked_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstacked_val_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstacked_val_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m test_loss, test_accuracy = model.evaluate(stacked_test_images, stacked_test_labels)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Eddie\\Documents\\CodeInstitute Workspace\\Capstone Project\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Eddie\\Documents\\CodeInstitute Workspace\\Capstone Project\\venv\\Lib\\site-packages\\optree\\ops.py:766\u001b[39m, in \u001b[36mtree_map\u001b[39m\u001b[34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[39m\n\u001b[32m    764\u001b[39m leaves, treespec = _C.flatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[32m    765\u001b[39m flat_args = [leaves] + [treespec.flatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[43m.\u001b[49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mMemoryError\u001b[39m: Unable to allocate 494. MiB for an array with shape (120, 600, 600, 3) and data type float32"
          ]
        }
      ],
      "source": [
        "model.fit(stacked_images, stacked_labels, epochs=4, validation_data=(stacked_val_images, stacked_val_labels))\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(stacked_test_images, stacked_test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In cases where you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.12 (capstone-venv)",
      "language": "python",
      "name": "capstone-venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
